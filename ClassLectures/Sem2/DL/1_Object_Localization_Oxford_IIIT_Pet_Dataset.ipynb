{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "rDL5UxUs0nUu",
        "KIN4CgX185lH"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKxFOKUUo_0e"
      },
      "source": [
        "#### Downlad the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3sRwJ_mo49J"
      },
      "source": [
        "#Download both images and annotations\n",
        "!wget -q http://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\n",
        "!wget -q http://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aikHskRpWE8"
      },
      "source": [
        "#Check current directory to make sure data is downloaded\n",
        "!ls -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXSZi1law-BX"
      },
      "source": [
        "#unzip the tar files downloaded abve\n",
        "!tar xf images.tar.gz\n",
        "!tar xf annotations.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvrVCc0bxSvi"
      },
      "source": [
        "#Explore directories\n",
        "!ls -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVRcONh64ESo"
      },
      "source": [
        "!ls -l images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myD1MThUbylY"
      },
      "source": [
        "!ls -l images | wc -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBuZuw2WaQVx"
      },
      "source": [
        "!ls -l annotations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLXGogOMb4cb"
      },
      "source": [
        "!ls -l annotations/xmls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pRBcHsRBOMq"
      },
      "source": [
        "#Check the xml annotations\n",
        "!ls -l annotations/xmls | wc -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob"
      ],
      "metadata": {
        "id": "dwBCpja38zqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(glob.glob('annotations/xmls/*.xml'))"
      ],
      "metadata": {
        "id": "nymOdv1C82Dx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yj7Qh4NGgET"
      },
      "source": [
        "!cat annotations/xmls/yorkshire_terrier_18.xml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUfVehWP0WLj"
      },
      "source": [
        "#Install tidy to review xml files\n",
        "!sudo apt-get install tidy --quiet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXWETTacxV4h"
      },
      "source": [
        "#Check one of the xml file to understand annotations\n",
        "!tidy -xml -i annotations/xmls/wheaten_terrier_170.xml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDL5UxUs0nUu"
      },
      "source": [
        "#### Convert XML to CSV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5b5pJF20r3k"
      },
      "source": [
        "#Mount Google drive (change code for local machine). We need to copy generate_dataset.py script to current directory\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wh8IQWfZ-cnJ"
      },
      "source": [
        "#Copy generate_dataset.py file to current directory\n",
        "!cp \"/content/drive/MyDrive/Deep learning Mtech Residency rev+LI/DL Materials Sagarika/RK content/ACV-I/Notebooks/Localization/generate_dataset.py\" ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "hgtejYZ_y6jD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8pqOIYVE8ty"
      },
      "source": [
        "!ls -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZuckkwA1gHb"
      },
      "source": [
        "#Move all xml files to images folder, this is needed for python script used next\n",
        "!mv annotations/xmls/* images/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZqrnN7t1nCv"
      },
      "source": [
        "#Build csv file for both training and test dataset\n",
        "!python generate_dataset.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZirB08cx2SBr"
      },
      "source": [
        "!ls -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIN4CgX185lH"
      },
      "source": [
        "#### Visualize Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JvG_JZf88KP"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98RE4JSU2bdF"
      },
      "source": [
        "#Read csv file as pandas dataframe, csv file has no header\n",
        "train_df = pd.read_csv('train.csv', header=None,\n",
        "                       names=['File', 'Height','Width','xmin',\n",
        "                              'ymin','xmax', 'ymax','Class','Label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-U19sPMCQeV"
      },
      "source": [
        "print(train_df.shape)\n",
        "train_df.sample(n=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBQRF_RC4Pzc"
      },
      "source": [
        "#Create a dictionary to hold label and corresponding class name\n",
        "num_classes = train_df['Label'].unique()\n",
        "label_class_dict = dict(zip(train_df['Label'], train_df['Class']))\n",
        "label_class_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdex_ymSFhc4"
      },
      "source": [
        "num_classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2A6QVyV_T1yp"
      },
      "source": [
        "len(num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-56OxVKeGbzo"
      },
      "source": [
        "label_class_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iemaa5bXWzg"
      },
      "source": [
        "train_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTi8vgryCqh4"
      },
      "source": [
        "Show images with bounding box"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-p3ne1E95Ru"
      },
      "source": [
        "#Pickup a random image number\n",
        "img_num = np.random.randint(0, train_df.shape[0])\n",
        "img_num = 832\n",
        "#Read the image and draw a rectangle as per bounding box information\n",
        "img = cv2.imread(train_df.loc[img_num,'File'])\n",
        "img = cv2.resize(img,(224, 224))\n",
        "w = train_df.loc[img_num, 'Width']\n",
        "h = train_df.loc[img_num, 'Height']\n",
        "x_ratio = 224/w\n",
        "y_ratio = 224/h\n",
        "\n",
        "cv2.rectangle(img,\n",
        "             (int(train_df.loc[img_num, 'xmin']*x_ratio),int(train_df.loc[img_num, 'ymin']*y_ratio)),\n",
        "             (int(train_df.loc[img_num, 'xmax']*x_ratio),int(train_df.loc[img_num, 'ymax']*y_ratio)),\n",
        "             (0,255,0),\n",
        "             2)\n",
        "\n",
        "#Convert BGR format (used by opencv to RGB format used by matplotlib)\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "#Draw image using matplotlib\n",
        "print(train_df.loc[img_num, 'Class'])\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zZ1iGShfpWb"
      },
      "source": [
        "img_num"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fr2d9x6o8ujS"
      },
      "source": [
        "train_df.loc[img_num, :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOnn8CixMEcw"
      },
      "source": [
        "#Read the validation csv file\n",
        "test_df = pd.read_csv('validation.csv', header=None,\n",
        "                       names=['File', 'Height','Width','xmin',\n",
        "                              'ymin','xmax', 'ymax','Class','Label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yON7EYPHTa7w"
      },
      "source": [
        "train_df.shape, test_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONbePE8pDUap"
      },
      "source": [
        "#### Build a Batch Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJHj-NNvEhpa"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8RGtJJKEmPK"
      },
      "source": [
        "img_size = 224"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gG9qxvqfDXgJ"
      },
      "source": [
        "def batch_generator(df, batch_size=32):\n",
        "\n",
        "    while True:\n",
        "\n",
        "        #Create indexes\n",
        "        image_nums = np.random.randint(0,df.shape[0], size=batch_size)\n",
        "\n",
        "        #Create empty arrays\n",
        "        #1. To hold image input\n",
        "        batch_images = np.zeros(shape=(batch_size, img_size, img_size, 3))\n",
        "\n",
        "        #Classification Labels\n",
        "        batch_labels = np.zeros(shape=(batch_size, len(num_classes)))\n",
        "\n",
        "        #Regression labels - 4 numbers per example image\n",
        "        batch_bboxes = np.zeros(shape=(batch_size, 4))\n",
        "\n",
        "\n",
        "        for i in range(batch_size):\n",
        "\n",
        "            #Read image and resize\n",
        "            img = tf.keras.preprocessing.image.load_img(df.loc[image_nums[i], 'File'],\n",
        "                                                        target_size=(img_size, img_size))\n",
        "\n",
        "            #Convert to numpy array\n",
        "            img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "\n",
        "            #Update batch\n",
        "            batch_images[i] = img_array\n",
        "\n",
        "            #Read image classification label & convert to one hot vector\n",
        "            cl_label = df.loc[image_nums[i], 'Label']\n",
        "            cl_label = tf.keras.utils.to_categorical(cl_label, num_classes=len(num_classes))\n",
        "            batch_labels[i] = cl_label\n",
        "\n",
        "            #Read and resize bounding box co-ordinates\n",
        "            img_width = df.loc[image_nums[i], 'Width']\n",
        "            img_height = df.loc[image_nums[i], 'Height']\n",
        "\n",
        "            xmin = df.loc[image_nums[i], 'xmin'] * img_size/img_width\n",
        "            xmax = df.loc[image_nums[i], 'xmax'] * img_size/img_width\n",
        "\n",
        "            ymin = df.loc[image_nums[i], 'ymin'] * img_size/img_height\n",
        "            ymax = df.loc[image_nums[i], 'ymax'] * img_size/img_height\n",
        "\n",
        "            #We will ask model to predict xmin, ymin, width and height of bounding box\n",
        "            batch_bboxes[i] = [xmin, ymin, xmax-xmin, ymax-ymin]\n",
        "\n",
        "        #Normalize batch images as per Pre-trained model to be used\n",
        "        for i in range(batch_size):\n",
        "            batch_images[i] = tf.keras.applications.resnet50.preprocess_input(batch_images[i])\n",
        "\n",
        "        #Make bounding boxes (x, y, w, h) as numbers between 0 and 1 - this seems to work better\n",
        "        batch_bboxes = batch_bboxes /img_size\n",
        "\n",
        "        #Return batch - use yield function to make it a python generator\n",
        "        yield batch_images, [batch_labels, batch_bboxes]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2Fw6l71Sig-"
      },
      "source": [
        "gen = batch_generator(train_df, batch_size=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9Hxm4_c075t"
      },
      "source": [
        "gen"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cylN-wK8SqEB"
      },
      "source": [
        "X, y = next(gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtOyEuKWvqKE"
      },
      "source": [
        "print(X.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNIBLPKI1KUJ"
      },
      "source": [
        "X[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(y)"
      ],
      "metadata": {
        "id": "DYe9jmD17HAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9LebH2slKf3"
      },
      "source": [
        "y[0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1sE1AfSq_yK"
      },
      "source": [
        "#Classification\n",
        "y[0][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nF5WvnOy_aTX"
      },
      "source": [
        "y[1].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a2l4Gv8lTXb"
      },
      "source": [
        "#Regression\n",
        "y[1][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFGPcGaMJt9-"
      },
      "source": [
        "#### Build the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVXicG2xKBoq"
      },
      "source": [
        "Load Pre-Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBPc2TXuJn5m"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "model = tf.keras.applications.ResNet50(include_top=False, #Do not include FC layer at the end\n",
        "                                       input_shape=(img_size, img_size, 3),\n",
        "                                       weights='imagenet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvPcn5zmv0H5"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z30I35deKR2_"
      },
      "source": [
        "Freeze all layers of Pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_G00NdDiMLkx"
      },
      "source": [
        "len(model.layers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nsafx9zlKEzA"
      },
      "source": [
        "for layer in model.layers:\n",
        "    layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itYAVviBgJW4"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s77uFZ5gh-25"
      },
      "source": [
        "model.output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ochVcQl_Knjg"
      },
      "source": [
        "Add layers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#get Output layer of Pre-trained model\n",
        "x1 = model.output"
      ],
      "metadata": {
        "id": "aYbY0rl9X_-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x1"
      ],
      "metadata": {
        "id": "5frjz1AaYBxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Flatten the output to feed to Dense layer\n",
        "#x2 = tf.keras.layers.GlobalAveragePooling2D()(x1)\n",
        "x2 = tf.keras.layers.Conv2D(32, (1,1), activation='relu')(x1)"
      ],
      "metadata": {
        "id": "VRAa1MrEYa3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x2"
      ],
      "metadata": {
        "id": "tjEGfVbhYdPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Add Dropout\n",
        "#x3 = tf.keras.layers.Dropout(0.5)(x2)\n",
        "x3 = tf.keras.layers.BatchNormalization()(x2)"
      ],
      "metadata": {
        "id": "AwAbmdR0YkcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x3"
      ],
      "metadata": {
        "id": "IyyKIWQhYliK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrdSJfSFKXIH"
      },
      "source": [
        "#Flatten\n",
        "x4 = tf.keras.layers.Flatten()(x3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgQBof80TZZ0"
      },
      "source": [
        "x4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSsesgHCKuq0"
      },
      "source": [
        "Build layer for Classification Label output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUyBwuxlKt67"
      },
      "source": [
        "#Classification\n",
        "label_output = tf.keras.layers.Dense(37,\n",
        "                                     activation='softmax',\n",
        "                                     name='class_op')(x4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bksL8On7tZ5f"
      },
      "source": [
        "label_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smOcT5VLK6BA"
      },
      "source": [
        "Build layer for bounding box output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ujk5IXzIK9O1"
      },
      "source": [
        "#Regression\n",
        "bbox_output = tf.keras.layers.Dense(4,\n",
        "                                    activation='sigmoid',\n",
        "                                    name='reg_op')(x4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9roF0YmBuQ4a"
      },
      "source": [
        "bbox_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSvjuIa2LlOY"
      },
      "source": [
        "Finalize the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3frSPd3Lj7i"
      },
      "source": [
        "#Non Sequential model as it has two different outputs\n",
        "final_model = tf.keras.models.Model(inputs=model.input, #Pre-trained model input as input layer\n",
        "                                    outputs=[label_output,bbox_output]) #Output layer added"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvXbMqx_sOCh"
      },
      "source": [
        "final_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KpqhepoiAfe"
      },
      "source": [
        "Define function to calculate IoU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ww0PFGg6ql3C"
      },
      "source": [
        "def calculate_iou(y_true, y_pred):\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    Input:\n",
        "    Keras provides the input as numpy arrays with shape (batch_size, num_columns).\n",
        "\n",
        "    Arguments:\n",
        "    y_true -- first box, numpy array with format [x, y, width, height, conf_score]\n",
        "    y_pred -- second box, numpy array with format [x, y, width, height, conf_score]\n",
        "    x any y are the coordinates of the top left corner of each box.\n",
        "\n",
        "    Output: IoU of type float32. (This is a ratio. Max is 1. Min is 0.)\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for i in range(0,y_true.shape[0]):\n",
        "\n",
        "        # set the types so we are sure what type we are using\n",
        "        y_true = np.array(y_true, dtype=np.float32)\n",
        "        y_pred = np.array(y_pred, dtype=np.float32)\n",
        "\n",
        "        #print(y_true.shape)\n",
        "        #print(y_pred.shape)\n",
        "        # boxTrue\n",
        "        x_boxTrue_tleft = y_true[i,0]  # numpy index selection\n",
        "        y_boxTrue_tleft = y_true[i,1]\n",
        "        boxTrue_width = y_true[i,2]\n",
        "        boxTrue_height = y_true[i,3]\n",
        "        area_boxTrue = (boxTrue_width * boxTrue_height)\n",
        "\n",
        "        # boxPred\n",
        "        x_boxPred_tleft = y_pred[i,0]\n",
        "        y_boxPred_tleft = y_pred[i,1]\n",
        "        boxPred_width = y_pred[i,2]\n",
        "        boxPred_height = y_pred[i,3]\n",
        "        area_boxPred = (boxPred_width * boxPred_height)\n",
        "\n",
        "        # calculate the bottom right coordinates for boxTrue and boxPred\n",
        "\n",
        "        # boxTrue\n",
        "        x_boxTrue_br = x_boxTrue_tleft + boxTrue_width\n",
        "        y_boxTrue_br = y_boxTrue_tleft + boxTrue_height # Version 2 revision\n",
        "\n",
        "        # boxPred\n",
        "        x_boxPred_br = x_boxPred_tleft + boxPred_width\n",
        "        y_boxPred_br = y_boxPred_tleft + boxPred_height # Version 2 revision\n",
        "\n",
        "\n",
        "        # calculate the top left and bottom right coordinates for the intersection box, boxInt\n",
        "\n",
        "        # boxInt - top left coords\n",
        "        x_boxInt_tleft = np.max([x_boxTrue_tleft,x_boxPred_tleft])\n",
        "        y_boxInt_tleft = np.max([y_boxTrue_tleft,y_boxPred_tleft]) # Version 2 revision\n",
        "\n",
        "        # boxInt - bottom right coords\n",
        "        x_boxInt_br = np.min([x_boxTrue_br,x_boxPred_br])\n",
        "        y_boxInt_br = np.min([y_boxTrue_br,y_boxPred_br])\n",
        "\n",
        "        # Calculate the area of boxInt, i.e. the area of the intersection\n",
        "        # between boxTrue and boxPred.\n",
        "        # The np.max() function forces the intersection area to 0 if the boxes don't overlap.\n",
        "\n",
        "\n",
        "        # Version 2 revision\n",
        "        area_of_intersection = \\\n",
        "        np.max([0,(x_boxInt_br - x_boxInt_tleft)]) * np.max([0,(y_boxInt_br - y_boxInt_tleft)])\n",
        "\n",
        "        iou = area_of_intersection / ((area_boxTrue + area_boxPred) - area_of_intersection)\n",
        "\n",
        "\n",
        "        # This must match the type used in py_func\n",
        "        iou = np.array(iou, dtype=np.float32)\n",
        "\n",
        "        # append the result to a list at the end of each loop\n",
        "        results.append(iou)\n",
        "\n",
        "    # return the mean IoU score for the batch\n",
        "    return np.mean(results)\n",
        "\n",
        "\n",
        "\n",
        "def IoU(y_true, y_pred):\n",
        "\n",
        "    # Note: the type float32 is very important. It must be the same type as the output from\n",
        "    # the python function above or you too may spend many late night hours\n",
        "    # trying to debug and almost give up.\n",
        "\n",
        "    iou = tf.py_function(calculate_iou, [y_true, y_pred], tf.float32)\n",
        "\n",
        "    return iou"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfVR7QqYLyNz"
      },
      "source": [
        "final_model.compile(optimizer='adam',\n",
        "                    loss={'reg_op':'mse', 'class_op':'categorical_crossentropy'},\n",
        "                    loss_weights={'reg_op':1, 'class_op':1},\n",
        "                    metrics={'reg_op':[IoU], 'class_op':['accuracy']})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RQg_TeWL8CC"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLOR7EApL6cl"
      },
      "source": [
        "#Create train and test generator\n",
        "batchsize = 64\n",
        "train_generator = batch_generator(train_df, batch_size=batchsize) #batchsize can be changed\n",
        "test_generator = batch_generator(test_df, batch_size=batchsize)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGjtvmc_zaIh"
      },
      "source": [
        "final_model.fit(train_generator,\n",
        "                epochs=5,\n",
        "                steps_per_epoch= train_df.shape[0]//batchsize,\n",
        "                validation_data=test_generator,\n",
        "                validation_steps = test_df.shape[0]//batchsize)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmqypNf28WGS"
      },
      "source": [
        "final_model.compile(optimizer='adam',\n",
        "                    loss={'reg_op':'mse', 'class_op':'categorical_crossentropy'},\n",
        "                    loss_weights={'reg_op':10, 'class_op':1},\n",
        "                    metrics={'reg_op':[IoU], 'class_op':['accuracy']})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8xqseOz8fk0"
      },
      "source": [
        "final_model.fit(train_generator,\n",
        "                epochs=10,\n",
        "                initial_epoch=5,\n",
        "                steps_per_epoch= train_df.shape[0]//batchsize,\n",
        "                validation_data=test_generator,\n",
        "                validation_steps = test_df.shape[0]//batchsize)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_model.fit(train_generator,\n",
        "                epochs=15,\n",
        "                initial_epoch=10,\n",
        "                steps_per_epoch= train_df.shape[0]//batchsize,\n",
        "                validation_data=test_generator,\n",
        "                validation_steps = test_df.shape[0]//batchsize)"
      ],
      "metadata": {
        "id": "fnxq8WfSES41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5msq1-6tX3lJ"
      },
      "source": [
        "final_model.save('pet_dataset_localization.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_model.input"
      ],
      "metadata": {
        "id": "_nN109_Dnrl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RT_TJaPWX2PK"
      },
      "source": [
        "#### Model Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyrMXl9EdiSt"
      },
      "source": [
        "def predict_and_draw(image_num, df):\n",
        "\n",
        "    #Load image\n",
        "    img = tf.keras.preprocessing.image.load_img(df.loc[image_num, 'File'])\n",
        "    w, h = img.size\n",
        "\n",
        "    #Prepare input for model\n",
        "    #1. Resize image\n",
        "    img_resized = img.resize((img_size, img_size))\n",
        "    #2. Conver to array and make it a batch of 1\n",
        "    input_array = tf.keras.preprocessing.image.img_to_array(img_resized)\n",
        "    input_array = np.expand_dims(input_array, axis=0)\n",
        "\n",
        "    #3. Normalize image data\n",
        "    input_array = tf.keras.applications.resnet50.preprocess_input(input_array)\n",
        "\n",
        "    #Prediction\n",
        "    pred = final_model.predict(input_array)\n",
        "    #Get classification and regression predictions\n",
        "    label_pred, bbox_pred = pred[0][0], pred[1][0]\n",
        "\n",
        "    #print('Class label prediction', label_pred)\n",
        "    #print('Boundary box prediction', bbox_pred)\n",
        "\n",
        "    #Get Label with highest probability\n",
        "    pred_class = label_class_dict[np.argmax(label_pred)]\n",
        "\n",
        "    #Read actual label and bounding box\n",
        "    act_class = df.loc[image_num, 'Class']\n",
        "    xmin, ymin, xmax, ymax = df.loc[image_num, ['xmin', 'ymin', 'xmax', 'ymax']]\n",
        "\n",
        "    print('Actual Label :', act_class, '\\nPredicted Label: ', pred_class)\n",
        "\n",
        "    #Draw bounding boxes - Actual (Red) and Predicted(Green)\n",
        "    img = cv2.imread(df.loc[image_num, 'File'])\n",
        "\n",
        "    #Draw actual bounding box - RED\n",
        "    img = cv2.rectangle(img, (xmin, ymin),\n",
        "                        (xmax, ymax), (0,0,255), 3)\n",
        "\n",
        "    #Draw predicted bounding box\n",
        "    img = cv2.rectangle(img, (int(bbox_pred[0]*w), int(bbox_pred[1]*h)),\n",
        "                        (int((bbox_pred[0]+bbox_pred[2])*w),\n",
        "                         int((bbox_pred[1]+bbox_pred[3])*h)), (0,255,0), 3)\n",
        "\n",
        "    #Display the picture\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.imshow(img)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DH0bH4YiYZ4b"
      },
      "source": [
        "#Predict on Test Dataset\n",
        "image_num = np.random.randint(0, test_df.shape[0])\n",
        "predict_and_draw(image_num, test_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoiHsbD5y3GP"
      },
      "source": [
        "img = tf.keras.preprocessing.image.load_img(test_df.loc[0, 'File'], target_size=(224,224))\n",
        "img_array = tf.keras.preprocessing.image.img_to_array(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cq0tfsMpzBEU"
      },
      "source": [
        "img_array.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1eNVnlPzFRC"
      },
      "source": [
        "final_model.input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFZz1eZCzTeG"
      },
      "source": [
        "np.expand_dims(img_array, axis=0).shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPwmXqgazOZ1"
      },
      "source": [
        "final_model.predict(np.expand_dims(img_array, axis=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hyWoiFvsEAiq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}